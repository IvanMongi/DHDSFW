{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprescindible\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to avoid some warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to draw some graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seaborn and matplotlib default theme\n",
    "sns.set_theme()\n",
    "_sns_plotting_contex_ = sns.plotting_context()\n",
    "sns.plotting_context('poster')\n",
    "\n",
    "# set seaborn and matplotlib style to ...\n",
    "# plt.style.use('classic')\n",
    "sns.mpl.rcParams['axes.titlesize'] = 18\n",
    "sns.mpl.rcParams['axes.labelsize'] = 14\n",
    "\n",
    "# to use HTML codes within IPpython.display function\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_train_read() :\n",
    "    u''' Reads and prepare data from blog feedback data train set\n",
    "    \n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(\"./data/blogData_train.csv\", header=None)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    header = pd.read_csv(\"./data/blogData_label.csv\", header=None)\n",
    "    header = list(header[0])\n",
    "    \n",
    "    if len(header) != data.shape[1] :\n",
    "        raise Exception('Los encabezados y la cantidad de caracter√≠sticas NO COINCIDE !!!')\n",
    "\n",
    "    data.columns = header\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49203, 281)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = blogData_train_read()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_labels(data) :\n",
    "    u''' Create a dictionary with some keys associates to list of features in the final work dataframe\n",
    "    \n",
    "    '''\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    labels = dict()\n",
    "\n",
    "    labels['sd_nc_total_before_BT'] = columns[0:5]\n",
    "    labels['sd_nc_24_before_BT'] = columns[5:10]\n",
    "    labels['sd_nc_between_24_48'] = columns[10:15]\n",
    "    labels['sd_nc_first_24_BT'] = columns[15:20]\n",
    "    labels['sd_nc_diff_24_48'] = columns[20:25]\n",
    "    \n",
    "    labels['sd_nl_total_before_BT'] = columns[25:30]\n",
    "    labels['sd_nl_24_before_BT'] = columns[30:35]\n",
    "    labels['sd_nl_between_24_48'] = columns[35:40]\n",
    "    labels['sd_nl_first_24_BT'] = columns[40:45]\n",
    "    labels['sd_nl_diff_24_48'] = columns[45:50]\n",
    "    \n",
    "    labels['nc_total_before_BT'] = columns[50:51]\n",
    "    labels['nc_24_before_BT'] = columns[51:52]\n",
    "    labels['nc_between_24_48'] = columns[52:53]\n",
    "    labels['nc_first_24_BT'] = columns[53:54]\n",
    "    labels['nc_diff_24_48'] = columns[54:55]\n",
    "    \n",
    "    labels['nl_total_before_BT'] = columns[55:56]\n",
    "    labels['nl_24_before_BT'] = columns[56:57]\n",
    "    labels['nl_between_24_48'] = columns[57:58]\n",
    "    labels['nl_first_24_BT'] = columns[58:59]\n",
    "    labels['nl_diff_24_48'] = columns[59:60]\n",
    "    \n",
    "    labels['nc'] = columns[50:55]\n",
    "    labels['nl'] = columns[55:60]\n",
    "\n",
    "    labels['timelength_post_BT'] = columns[60:61]\n",
    "    labels['length_post'] = columns[61:62]\n",
    "    \n",
    "    labels['tl_post'] = columns[60:62]\n",
    "\n",
    "    labels['frequent_word'] = columns[62:262]\n",
    "\n",
    "    labels['weekday_BT'] = columns[262:269]\n",
    "    labels['weekday_post'] = columns[269:276]\n",
    "    \n",
    "    labels['parents'] = columns[276:280]\n",
    "    labels['comments'] = columns[280:281]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = blogData_labels(data)\n",
    "target = 'comments'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = lambda v: round(v, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Regression_Models\"></a>\n",
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RM_Estimator :\n",
    "    u'''\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, name, estimator, gs_param_grid=None) :\n",
    "        self.name = name\n",
    "        self.estimator = estimator\n",
    "        self.gs_param_grid = gs_param_grid\n",
    "        \n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_evaluate(rm_result, rm_models, X_train, y_train) :\n",
    "    u'''\n",
    "    '''\n",
    "    \n",
    "    for rm in rm_models :\n",
    "\n",
    "        scoring = 'neg_root_mean_squared_error'\n",
    "        cv = StratifiedKFold(n_splits=3, random_state=11, shuffle=True)\n",
    "        \n",
    "        gs = GridSearchCV(\n",
    "            estimator=rm.estimator, # scikit-learn estimator interface\n",
    "            param_grid=rm.gs_param_grid, # dictionart key=parametrer, value=list of paraameter posible values\n",
    "            scoring=scoring, # strategy to evaluate performance of cross-validated\n",
    "            n_jobs=-2, # jobs in parallel -2 : all processors minus one\n",
    "            refit=True, # refit estimator using best parameters\n",
    "            cv=cv, # cross-validated splitting strategy\n",
    "            return_train_score=False, # include training scores\n",
    "            verbose=1 # display fold parameters, score, time, ...\n",
    "        )\n",
    "        \n",
    "        print('Gridsearch para', rm.name, '...')\n",
    "\n",
    "        gs_time = time.time()\n",
    "        gs.fit(X_train, y_train)\n",
    "        gs_time = ROUND(time.time() - gs_time)\n",
    "        \n",
    "        y_pred = gs.predict(X_train)\n",
    "        gs_rmse = ROUND(np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "\n",
    "        rm_result = rm_result.append(\n",
    "            pd.Series(\n",
    "                data=[rm.name, \n",
    "                      gs.best_params_, \n",
    "                      gs_time, \n",
    "                      gs_rmse\n",
    "                     ], \n",
    "                index=rm_result.columns\n",
    "                ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    return rm_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rm_models = []\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Linear Regression',\n",
    "#         estimator=LinearRegression(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Ridge',\n",
    "#         estimator=Ridge(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Lasso',\n",
    "#         estimator=Lasso(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Elastic Net',\n",
    "#         estimator=ElasticNet(),\n",
    "#         gs_param_grid={\n",
    "#             'alpha' : [1.0], \n",
    "#             'l1_ratio' : [0, 0.5, 1] # 0 : no L2 penalty (Ridge);  1 : no L1 penalty (Lasso)\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='K-Nearest Neighbors',\n",
    "#         estimator=KNeighborsRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'n_jobs' : [-2], \n",
    "#             'n_neighbors' : [5, 10], \n",
    "#             'p' : [2], # euclidian_distance\n",
    "#             'weights' : ['uniform'] # equally weighted\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Random Forest Regressor',\n",
    "#         estimator=RandomForestRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'max_depth' : [3], \n",
    "#             'n_estimators' : [500], \n",
    "#             'n_jobs' : [-2], \n",
    "#             'random_state' : [127]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Gradient Boosting Regressor',\n",
    "#         estimator=GradientBoostingRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'learning_rate' : [0.1, 0.2], \n",
    "#             'max_depth' : [3], \n",
    "#             'n_estimators' : [500], \n",
    "#             'random_state' : [127], \n",
    "#             'verbose' : [0]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='XGBoost (default)',\n",
    "#         estimator=xgb.XGBRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'gamma' : [0], # (min_split_loss) minimum loss reduction\n",
    "#             'learning_rate' : [0.3], # (eta) step size shrinkage\n",
    "#             'max_depth' : [6], # maximum depth of tree\n",
    "#             'n_estimators' : [500], \n",
    "#             'n_jobs' : [-2], # jobs in parallel -2 : all processors minus one\n",
    "#             'random_state' : [127], \n",
    "#             'reg_alpha' : [0], # (alpha) L1 regularization\n",
    "#             'reg_lambda' : [1] # (lambda) L2 regularization\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "rm_models.append(\n",
    "    RM_Estimator(\n",
    "        name='XGBoost L1 y L2',\n",
    "        estimator=xgb.XGBRegressor(),\n",
    "        gs_param_grid={\n",
    "            'gamma' : [1], \n",
    "            'learning_rate' : [0.2], \n",
    "            'max_depth' : [12], \n",
    "            'n_estimators' : [1000], \n",
    "            'n_jobs' : [-2], # jobs in parallel -2 : all processors minus one\n",
    "            'random_state' : [127], \n",
    "            'reg_alpha' : [1000], # L1 regularization\n",
    "            'reg_lambda' : [1000] # L2 regularization\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data.drop(columns=[target])\n",
    "y_train = data[target].copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(\n",
    "    data=scaler.transform(X_train), \n",
    "    columns=list(X_train.columns)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore code\n",
    "if False :\n",
    "    rm_columns = ['model', 'params', 'time', 'RMSE']\n",
    "    rm_result = pd.DataFrame(columns=rm_columns)\n",
    "\n",
    "    rm_result = rm_evaluate(rm_result, rm_models, X_train, y_train)\n",
    "\n",
    "    pd.options.display.max_colwidth = 500 \n",
    "    rm_result.sort_values(by=['RMSE'], axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "{'gamma': 1, 'learning_rate': 0.2, 'max_depth': 12, 'n_estimators': 1000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000} : RMSE -> 14.91 (*)\n",
    "\n",
    "{'gamma': 1, 'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 1000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000} : RMSE -> 15.45\n",
    "\n",
    "{'gamma': 1, 'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 1000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000} : RMSE -> 16.36\n",
    "\n",
    "{'gamma': 1, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 2000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000} : RMSE -> 17.69 \n",
    "\n",
    "{'gamma': 1, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 1000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000} : RMSE -> 17.69\n",
    "\n",
    "{'gamma': 1, 'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 1000, 'n_jobs': -2, 'random_state': 127, 'reg_alpha': 1500, 'reg_lambda': 1500} : RMSE -> 19.52\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=1, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
       "             max_depth=12, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1000, n_jobs=-2,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=127,\n",
       "             reg_alpha=1000, reg_lambda=1000, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {\n",
    "    'gamma': 1, \n",
    "    'learning_rate': 0.2, \n",
    "    'max_depth': 12, \n",
    "    'n_estimators': 1000, \n",
    "    'n_jobs': -2, \n",
    "    'random_state': 127, \n",
    "    'reg_alpha': 1000, \n",
    "    'reg_lambda': 1000\n",
    "}\n",
    "\n",
    "model.set_params(\n",
    "    gamma=1, \n",
    "    learning_rate=0.2, \n",
    "    max_depth=12, \n",
    "    n_estimators=1000, \n",
    "    n_jobs=-2, \n",
    "    random_state=127, \n",
    "    reg_alpha=1000, \n",
    "    reg_lambda=1000\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(data=pd.Series(data=list(model.feature_importances_), name='value'))\n",
    "\n",
    "result.insert(loc=0, column='feature', value=pd.Series(data.columns, name='feature'))\n",
    "result.sort_values(by='value', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>median_nc_24_before_BT</td>\n",
       "      <td>0.157462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>std_nc_diff_24_48</td>\n",
       "      <td>0.153757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>std_nc_24_before_BT</td>\n",
       "      <td>0.123043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>media_nc_diff_24_48</td>\n",
       "      <td>0.070029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std_nc_total_before_BT</td>\n",
       "      <td>0.042128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>media_nc_total_before_BT</td>\n",
       "      <td>0.025601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>nl_first_24_BT</td>\n",
       "      <td>0.024752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>nc_diff_24_48</td>\n",
       "      <td>0.012668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>media_nc_between_24_48</td>\n",
       "      <td>0.010701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nc_24_before_BT</td>\n",
       "      <td>0.010268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>median_nc_between_24_48</td>\n",
       "      <td>0.010188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>timelength_post_BT</td>\n",
       "      <td>0.009992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std_nc_between_24_48</td>\n",
       "      <td>0.008625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>median_nc_total_before_BT</td>\n",
       "      <td>0.006339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>fw_184</td>\n",
       "      <td>0.005849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>fw_139</td>\n",
       "      <td>0.005548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>media_nc_24_before_BT</td>\n",
       "      <td>0.005155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>media_nl_total_before_BT</td>\n",
       "      <td>0.005126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>median_nl_first_24_BT</td>\n",
       "      <td>0.004913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>media_nc_first_24_BT</td>\n",
       "      <td>0.004370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>fw_85</td>\n",
       "      <td>0.004258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>fw_196</td>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>fw_7</td>\n",
       "      <td>0.004161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>fw_186</td>\n",
       "      <td>0.003979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>fw_127</td>\n",
       "      <td>0.003930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>fw_46</td>\n",
       "      <td>0.003754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max_nc_24_before_BT</td>\n",
       "      <td>0.003276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>fw_172</td>\n",
       "      <td>0.003152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>fw_164</td>\n",
       "      <td>0.002956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>fw_157</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature     value\n",
       "9       median_nc_24_before_BT  0.157462\n",
       "21           std_nc_diff_24_48  0.153757\n",
       "6          std_nc_24_before_BT  0.123043\n",
       "20         media_nc_diff_24_48  0.070029\n",
       "1       std_nc_total_before_BT  0.042128\n",
       "0     media_nc_total_before_BT  0.025601\n",
       "58              nl_first_24_BT  0.024752\n",
       "54               nc_diff_24_48  0.012668\n",
       "10      media_nc_between_24_48  0.010701\n",
       "51             nc_24_before_BT  0.010268\n",
       "14     median_nc_between_24_48  0.010188\n",
       "60          timelength_post_BT  0.009992\n",
       "11        std_nc_between_24_48  0.008625\n",
       "4    median_nc_total_before_BT  0.006339\n",
       "245                     fw_184  0.005849\n",
       "200                     fw_139  0.005548\n",
       "5        media_nc_24_before_BT  0.005155\n",
       "25    media_nl_total_before_BT  0.005126\n",
       "44       median_nl_first_24_BT  0.004913\n",
       "15        media_nc_first_24_BT  0.004370\n",
       "146                      fw_85  0.004258\n",
       "257                     fw_196  0.004231\n",
       "68                        fw_7  0.004161\n",
       "247                     fw_186  0.003979\n",
       "188                     fw_127  0.003930\n",
       "107                      fw_46  0.003754\n",
       "8          max_nc_24_before_BT  0.003276\n",
       "233                     fw_172  0.003152\n",
       "225                     fw_164  0.002956\n",
       "218                     fw_157  0.002900"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pepe = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 1,\n",
       " 'learning_rate': 0.2,\n",
       " 'max_depth': 12,\n",
       " 'n_estimators': 1000,\n",
       " 'n_jobs': -2,\n",
       " 'random_state': 127,\n",
       " 'reg_alpha': 1000,\n",
       " 'reg_lambda': 1000}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=None,\n",
       "             enable_categorical=False, gamma=1, gpu_id=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.2, max_delta_step=None, max_depth=12,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=-2, num_parallel_tree=None,\n",
       "             predictor=None, random_state=127, reg_alpha=1000, reg_lambda=1000,\n",
       "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "             validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pepe.set_params(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
