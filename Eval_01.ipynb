{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprescindible\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to avoid some warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to draw some graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seaborn and matplotlib default theme\n",
    "sns.set_theme()\n",
    "_sns_plotting_contex_ = sns.plotting_context()\n",
    "sns.plotting_context('poster')\n",
    "\n",
    "# set seaborn and matplotlib style to ...\n",
    "# plt.style.use('classic')\n",
    "sns.mpl.rcParams['axes.titlesize'] = 18\n",
    "sns.mpl.rcParams['axes.labelsize'] = 14\n",
    "\n",
    "# to use HTML codes within IPpython.display function\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_train_read() :\n",
    "    u''' Reads and prepare data from blog feedback data train set\n",
    "    \n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(\"./data/blogData_train.csv\", header=None)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    header = pd.read_csv(\"./data/blogData_label.csv\", header=None)\n",
    "    header = list(header[0])\n",
    "    \n",
    "    if len(header) != data.shape[1] :\n",
    "        raise Exception('Los encabezados y la cantidad de caracter√≠sticas NO COINCIDE !!!')\n",
    "\n",
    "    data.columns = header\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def blogData_test_read() :\n",
    "    u''' Reads and prepare data from blog feedback data test set\n",
    "    \n",
    "    '''\n",
    "\n",
    "    filepath = './data/test/'\n",
    "    filelist = [os.path.join(filepath, filename) for filename in os.listdir(filepath) if os.path.isfile(os.path.join(filepath, filename))]\n",
    "\n",
    "    test_raw = pd.DataFrame()\n",
    "\n",
    "    for filename in filelist :\n",
    "        temp_raw = pd.read_csv(filename, header=None)\n",
    "        temp_raw.drop_duplicates(inplace=True)\n",
    "        test_raw = test_raw.append(temp_raw)\n",
    "\n",
    "    return test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49203, 281)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = blogData_train_read()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_labels(data) :\n",
    "    u''' Create a dictionary with some keys associates to list of features in the final work dataframe\n",
    "    \n",
    "    '''\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    labels = dict()\n",
    "\n",
    "    labels['sd_nc_total_before_BT'] = columns[0:5]\n",
    "    labels['sd_nc_24_before_BT'] = columns[5:10]\n",
    "    labels['sd_nc_between_24_48'] = columns[10:15]\n",
    "    labels['sd_nc_first_24_BT'] = columns[15:20]\n",
    "    labels['sd_nc_diff_24_48'] = columns[20:25]\n",
    "    \n",
    "    labels['sd_nl_total_before_BT'] = columns[25:30]\n",
    "    labels['sd_nl_24_before_BT'] = columns[30:35]\n",
    "    labels['sd_nl_between_24_48'] = columns[35:40]\n",
    "    labels['sd_nl_first_24_BT'] = columns[40:45]\n",
    "    labels['sd_nl_diff_24_48'] = columns[45:50]\n",
    "    \n",
    "    labels['nc_total_before_BT'] = columns[50:51]\n",
    "    labels['nc_24_before_BT'] = columns[51:52]\n",
    "    labels['nc_between_24_48'] = columns[52:53]\n",
    "    labels['nc_first_24_BT'] = columns[53:54]\n",
    "    labels['nc_diff_24_48'] = columns[54:55]\n",
    "    \n",
    "    labels['nl_total_before_BT'] = columns[55:56]\n",
    "    labels['nl_24_before_BT'] = columns[56:57]\n",
    "    labels['nl_between_24_48'] = columns[57:58]\n",
    "    labels['nl_first_24_BT'] = columns[58:59]\n",
    "    labels['nl_diff_24_48'] = columns[59:60]\n",
    "    \n",
    "    labels['nc'] = columns[50:55]\n",
    "    labels['nl'] = columns[55:60]\n",
    "\n",
    "    labels['timelength_post_BT'] = columns[60:61]\n",
    "    labels['length_post'] = columns[61:62]\n",
    "    \n",
    "    labels['tl_post'] = columns[60:62]\n",
    "\n",
    "    labels['frequent_word'] = columns[62:262]\n",
    "\n",
    "    labels['weekday_BT'] = columns[262:269]\n",
    "    labels['weekday_post'] = columns[269:276]\n",
    "    \n",
    "    labels['parents'] = columns[276:280]\n",
    "    labels['comments'] = columns[280:281]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = blogData_labels(data)\n",
    "target = 'comments'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = lambda v: round(v, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Regression_Models\"></a>\n",
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Eval_Estimator :\n",
    "    u'''\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, name, estimator, params=None) :\n",
    "        self.name = name\n",
    "        self.estimator = estimator\n",
    "        self.params = params\n",
    "        \n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data.drop(columns=[target])\n",
    "\n",
    "X_train = X_train.iloc[:, 0:62].copy()\n",
    "y_train = data[target].copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(\n",
    "    data=scaler.transform(X_train), \n",
    "    columns=list(X_train.columns)\n",
    ")\n",
    "\n",
    "\n",
    "test_raw = blogData_test_read()\n",
    "X_test = test_raw.iloc[:,0:280]\n",
    "\n",
    "X_test = X_test.iloc[:, 0:62].copy()\n",
    "y_test = test_raw.iloc[:,-1]\n",
    "\n",
    "# using train scaler\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_models = []\n",
    "\n",
    "# eval_models.append(Eval_Estimator(\n",
    "#     name='Gradient Boosting Regressor', \n",
    "#     estimator=GradientBoostingRegressor(), \n",
    "#     params= {\n",
    "#         'learning_rate': 0.01, # shrinks the contribution of each tree\n",
    "#         'max_depth' : 4,\n",
    "#         'min_samples_split' : 5,\n",
    "#         'n_estimators' : 500, # boosting stages\n",
    "#         'subsamples' : 1, # value < 1.0 reduce variance and increase bias\n",
    "#     }\n",
    "# ))\n",
    "\n",
    "\n",
    "eval_models.append(Eval_Estimator(\n",
    "    name='XGBoost L1 y L2', \n",
    "    estimator=xgb.XGBRegressor(), \n",
    "    params= {\n",
    "        'eval_metric' : 'rmse', # root mean square error\n",
    "        'gamma': 1, # (min_split_loss) minimum loss reduction\n",
    "        'learning_rate': 0.2, # (eta) step size shrinkage\n",
    "        'max_depth': 8, # maximum depth of tree\n",
    "        # 'max_delta_step' : 0.5, # for classification extremely imbalanced\n",
    "        'n_estimators': 1000, \n",
    "        'n_jobs': -2, # jobs in parallel -2 : all processors minus one\n",
    "        'objective' : 'reg:squarederror', # regression with squared loss\n",
    "        'random_state': 127, \n",
    "        'reg_alpha': 1000, # (alpha) L1 regularization\n",
    "        'reg_lambda': 1000, # (lambda) L2 regularization\n",
    "        'subsample' : 0.1, # prevents overfitting\n",
    "    }\n",
    "))\n",
    "\n",
    "\n",
    "eval_models.append(Eval_Estimator(\n",
    "    name='XGBoost L1 y L2', \n",
    "    estimator=xgb.XGBRegressor(), \n",
    "    params= {\n",
    "        'eval_metric' : 'rmse', # root mean square error\n",
    "        'gamma': 1, # (min_split_loss) minimum loss reduction\n",
    "        'learning_rate': 0.2, # (eta) step size shrinkage\n",
    "        'max_depth': 8, # maximum depth of tree\n",
    "        # 'max_delta_step' : 0.5, # for classification extremely imbalanced\n",
    "        'n_estimators': 1000, \n",
    "        'n_jobs': -2, # jobs in parallel -2 : all processors minus one\n",
    "        'objective' : 'reg:squarederror', # regression with squared loss\n",
    "        'random_state': 127, \n",
    "        # 'reg_alpha': 1000, # (alpha) L1 regularization\n",
    "        # 'reg_lambda': 1000, # (lambda) L2 regularization\n",
    "        'subsample' : 0.1, # prevents overfitting\n",
    "    }\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train RMSE</th>\n",
       "      <th>test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost L1 y L2</td>\n",
       "      <td>{'eval_metric': 'rmse', 'gamma': 1, 'learning_...</td>\n",
       "      <td>24.0195</td>\n",
       "      <td>22.5527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost L1 y L2</td>\n",
       "      <td>{'eval_metric': 'rmse', 'gamma': 1, 'learning_...</td>\n",
       "      <td>12.4041</td>\n",
       "      <td>33.7544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model                                             params  \\\n",
       "0  XGBoost L1 y L2  {'eval_metric': 'rmse', 'gamma': 1, 'learning_...   \n",
       "1  XGBoost L1 y L2  {'eval_metric': 'rmse', 'gamma': 1, 'learning_...   \n",
       "\n",
       "   train RMSE  test RMSE  \n",
       "0     24.0195    22.5527  \n",
       "1     12.4041    33.7544  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_columns = ['model', 'params', 'train RMSE', 'test RMSE']\n",
    "eval_result = pd.DataFrame(columns=eval_columns)\n",
    "\n",
    "for m in eval_models :\n",
    "    m.estimator.set_params(**m.params)\n",
    "    m.estimator.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = m.estimator.predict(X_train)\n",
    "    rmse_train = ROUND(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "    y_pred_test = m.estimator.predict(X_test)\n",
    "    rmse_test = ROUND(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "    \n",
    "    eval_result = eval_result.append(\n",
    "        pd.Series(\n",
    "            data=[m.name, \n",
    "                  m.params, \n",
    "                  rmse_train, \n",
    "                  rmse_test\n",
    "                 ], \n",
    "            index=eval_result.columns), \n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "display(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False :\n",
    "    for m in eval_models :\n",
    "        print(m.name, m.estimator.get_params())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
