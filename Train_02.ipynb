{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprescindible\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to avoid some warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to draw some graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seaborn and matplotlib default theme\n",
    "sns.set_theme()\n",
    "_sns_plotting_contex_ = sns.plotting_context()\n",
    "sns.plotting_context('poster')\n",
    "\n",
    "# set seaborn and matplotlib style to ...\n",
    "# plt.style.use('classic')\n",
    "sns.mpl.rcParams['axes.titlesize'] = 18\n",
    "sns.mpl.rcParams['axes.labelsize'] = 14\n",
    "\n",
    "# to use HTML codes within IPpython.display function\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_train_read() :\n",
    "    u''' Reads and prepare data from blog feedback data train set\n",
    "    \n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(\"./data/blogData_train.csv\", header=None)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    header = pd.read_csv(\"./data/blogData_label.csv\", header=None)\n",
    "    header = list(header[0])\n",
    "    \n",
    "    if len(header) != data.shape[1] :\n",
    "        raise Exception('Los encabezados y la cantidad de caracter√≠sticas NO COINCIDE !!!')\n",
    "\n",
    "    data.columns = header\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49203, 281)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = blogData_train_read()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_labels(data) :\n",
    "    u''' Create a dictionary with some keys associates to list of features in the final work dataframe\n",
    "    \n",
    "    '''\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    labels = dict()\n",
    "\n",
    "    labels['sd_nc_total_before_BT'] = columns[0:5]\n",
    "    labels['sd_nc_24_before_BT'] = columns[5:10]\n",
    "    labels['sd_nc_between_24_48'] = columns[10:15]\n",
    "    labels['sd_nc_first_24_BT'] = columns[15:20]\n",
    "    labels['sd_nc_diff_24_48'] = columns[20:25]\n",
    "    \n",
    "    labels['sd_nl_total_before_BT'] = columns[25:30]\n",
    "    labels['sd_nl_24_before_BT'] = columns[30:35]\n",
    "    labels['sd_nl_between_24_48'] = columns[35:40]\n",
    "    labels['sd_nl_first_24_BT'] = columns[40:45]\n",
    "    labels['sd_nl_diff_24_48'] = columns[45:50]\n",
    "    \n",
    "    labels['nc_total_before_BT'] = columns[50:51]\n",
    "    labels['nc_24_before_BT'] = columns[51:52]\n",
    "    labels['nc_between_24_48'] = columns[52:53]\n",
    "    labels['nc_first_24_BT'] = columns[53:54]\n",
    "    labels['nc_diff_24_48'] = columns[54:55]\n",
    "    \n",
    "    labels['nl_total_before_BT'] = columns[55:56]\n",
    "    labels['nl_24_before_BT'] = columns[56:57]\n",
    "    labels['nl_between_24_48'] = columns[57:58]\n",
    "    labels['nl_first_24_BT'] = columns[58:59]\n",
    "    labels['nl_diff_24_48'] = columns[59:60]\n",
    "    \n",
    "    labels['nc'] = columns[50:55]\n",
    "    labels['nl'] = columns[55:60]\n",
    "\n",
    "    labels['timelength_post_BT'] = columns[60:61]\n",
    "    labels['length_post'] = columns[61:62]\n",
    "    \n",
    "    labels['tl_post'] = columns[60:62]\n",
    "\n",
    "    labels['frequent_word'] = columns[62:262]\n",
    "\n",
    "    labels['weekday_BT'] = columns[262:269]\n",
    "    labels['weekday_post'] = columns[269:276]\n",
    "    \n",
    "    labels['parents'] = columns[276:280]\n",
    "    labels['comments'] = columns[280:281]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = blogData_labels(data)\n",
    "target = 'comments'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = lambda v: round(v, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Regression_Models\"></a>\n",
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RM_Estimator :\n",
    "    u'''\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, name, estimator, gs_param_grid=None) :\n",
    "        self.name = name\n",
    "        self.estimator = estimator\n",
    "        self.gs_param_grid = gs_param_grid\n",
    "        \n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rm_gridsearch(estimator, param_grid) :\n",
    "    u''' Regression Model Grid Search for this final work\n",
    "    \n",
    "    '''\n",
    "\n",
    "    scoring = 'neg_root_mean_squared_error'\n",
    "    refit = True\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=11, shuffle=True)\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        estimator=estimator, # scikit-learn estimator interface\n",
    "        param_grid=param_grid, # dictionart key=parametrer, value=list of paraameter posible values\n",
    "        scoring=scoring, # strategy to evaluate performance of cross-validated\n",
    "        n_jobs=-2, # jobs in parallel -2 : all processors minus one\n",
    "        refit=refit, # refit estimator using best parameters\n",
    "        cv=cv, # cross-validated splitting strategy\n",
    "        return_train_score=False # include training scores\n",
    "    )\n",
    "\n",
    "    return gs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rm_models = []\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Linear Regression',\n",
    "#         estimator=LinearRegression(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Ridge',\n",
    "#         estimator=Ridge(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Lasso',\n",
    "#         estimator=Lasso(),\n",
    "#         gs_param_grid={\n",
    "#             'fit_intercept' : [True]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='Elastic Net',\n",
    "#         estimator=ElasticNet(),\n",
    "#         gs_param_grid={\n",
    "#             'alpha' : [1.0], \n",
    "#             'l1_ratio' : [0, 0.5, 1] # 0 : no L2 penalty (Ridge);  1 : no L1 penalty (Lasso)\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# rm_models.append(\n",
    "#     RM_Estimator(\n",
    "#         name='K-Nearest Neighbors',\n",
    "#         estimator=KNeighborsRegressor(),\n",
    "#         gs_param_grid={\n",
    "#             'n_neighbors' : [5, 10], \n",
    "#             'weights' : ['uniform'], # equally weighted\n",
    "#             'p' : [2], # euclidian_distance\n",
    "#             'n_jobs' : [-2]\n",
    "#         }\n",
    "#     )\n",
    "# )\n",
    "\n",
    "rm_models.append(\n",
    "    RM_Estimator(\n",
    "        name='Gradient Boosting Regressor',\n",
    "        estimator=GradientBoostingRegressor(),\n",
    "        gs_param_grid={\n",
    "            'learning_rate' : [0.1], \n",
    "            'n_estimators' : [100], \n",
    "            'subsample' : [1.0], \n",
    "            'criterion' : ['friedman_mse'], \n",
    "            'max_depth' : [3], \n",
    "            'random_state' : [127]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_evaluate(rm_result, rm_models, X_train_scl, y_train) :\n",
    "    u'''\n",
    "    '''\n",
    "    \n",
    "    rm_columns = rm_result.columns\n",
    "    rm_features = X_train_scl.shape[1]\n",
    "    \n",
    "    for rm in rm_models :\n",
    "\n",
    "        print('Gridsearch para', rm.name, rm_features, 'caracter√≠sticas ...', end=' ')\n",
    "\n",
    "        gs_time = time.time()\n",
    "        gs = rm_gridsearch(rm.estimator, rm.gs_param_grid)\n",
    "        gs.fit(X_train_scl, y_train)\n",
    "        gs_time = ROUND(time.time() - gs_time)\n",
    "        \n",
    "        print(gs_time, 'Segundos')\n",
    "\n",
    "        y_pred = gs.predict(X_train_scl)\n",
    "        gs_rmse = ROUND(np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "\n",
    "        rm_result = rm_result.append(\n",
    "            pd.Series(\n",
    "                data=[rm.name, rm_features, \n",
    "                      gs.best_params_, gs_time, gs_rmse], \n",
    "                index=rm_columns\n",
    "                ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    return rm_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data.drop(columns=[target])\n",
    "y_train = data[target].copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(\n",
    "    data=scaler.transform(X_train), \n",
    "    columns=list(X_train.columns)\n",
    ")\n",
    "\n",
    "rm_columns = ['model', 'features', 'params', 'time', 'RMSE']\n",
    "rm_result = pd.DataFrame(columns=rm_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 5 caracter√≠sticas ... 5.0606 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basic_features = labels['nc']\n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[basic_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 10 caracter√≠sticas ... 4.4577 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nc_nl_features = labels['nc'] + labels['nl']\n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[nc_nl_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 12 caracter√≠sticas ... 6.917 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nc_nl_tl_features = labels['nc'] + labels['nl'] + labels['tl_post'] \n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[nc_nl_tl_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 19 caracter√≠sticas ... 8.126 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weekday1_features = labels['nc'] + labels['nl'] + labels['tl_post'] + labels['weekday_BT']\n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[weekday1_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 26 caracter√≠sticas ... 9.5154 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weekday2_features = labels['nc'] + labels['nl'] + labels['tl_post'] + labels['weekday_BT'] + labels['weekday_post']\n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[weekday2_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 7 caracter√≠sticas ... 5.8995 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_features = labels['nc'] + labels['tl_post'] #+ labels['weekday_BT'] + labels['weekday_post']\n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[test_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 11 caracter√≠sticas ... 8.0079 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_features = labels['nc'] + labels['tl_post'] + labels['parents'] \n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[test_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 30 caracter√≠sticas ... 9.8786 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_features = labels['nc'] + labels['nl'] + labels['tl_post'] + labels['weekday_BT'] + labels['weekday_post'] + labels['parents'] \n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[test_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 230 caracter√≠sticas ... 35.902 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_features = labels['nc'] + labels['nl'] + labels['tl_post'] + labels['frequent_word'] + labels['weekday_BT'] + labels['weekday_post'] + labels['parents'] \n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train[test_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para Gradient Boosting Regressor 280 caracter√≠sticas ... 55.874 Segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test_features = labels['nc'] + labels['nl'] + labels['tl_post'] + labels['frequent_word'] + labels['weekday_BT'] + labels['weekday_post'] + labels['parents'] \n",
    "rm_result = rm_evaluate(rm_result, rm_models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>params</th>\n",
       "      <th>time</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>280</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>55.8740</td>\n",
       "      <td>21.5453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>230</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>35.9020</td>\n",
       "      <td>26.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>30</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>9.8786</td>\n",
       "      <td>26.8682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>26</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>9.5154</td>\n",
       "      <td>26.8983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>12</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>6.9170</td>\n",
       "      <td>26.9386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>19</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>8.1260</td>\n",
       "      <td>26.9410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>7</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>5.8995</td>\n",
       "      <td>27.4053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>11</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>8.0079</td>\n",
       "      <td>27.4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>4.4577</td>\n",
       "      <td>31.5142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'learning_rate':...</td>\n",
       "      <td>5.0606</td>\n",
       "      <td>31.7491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model features  \\\n",
       "9  Gradient Boosting Regressor      280   \n",
       "8  Gradient Boosting Regressor      230   \n",
       "7  Gradient Boosting Regressor       30   \n",
       "4  Gradient Boosting Regressor       26   \n",
       "2  Gradient Boosting Regressor       12   \n",
       "3  Gradient Boosting Regressor       19   \n",
       "5  Gradient Boosting Regressor        7   \n",
       "6  Gradient Boosting Regressor       11   \n",
       "1  Gradient Boosting Regressor       10   \n",
       "0  Gradient Boosting Regressor        5   \n",
       "\n",
       "                                              params     time     RMSE  \n",
       "9  {'criterion': 'friedman_mse', 'learning_rate':...  55.8740  21.5453  \n",
       "8  {'criterion': 'friedman_mse', 'learning_rate':...  35.9020  26.2993  \n",
       "7  {'criterion': 'friedman_mse', 'learning_rate':...   9.8786  26.8682  \n",
       "4  {'criterion': 'friedman_mse', 'learning_rate':...   9.5154  26.8983  \n",
       "2  {'criterion': 'friedman_mse', 'learning_rate':...   6.9170  26.9386  \n",
       "3  {'criterion': 'friedman_mse', 'learning_rate':...   8.1260  26.9410  \n",
       "5  {'criterion': 'friedman_mse', 'learning_rate':...   5.8995  27.4053  \n",
       "6  {'criterion': 'friedman_mse', 'learning_rate':...   8.0079  27.4566  \n",
       "1  {'criterion': 'friedman_mse', 'learning_rate':...   4.4577  31.5142  \n",
       "0  {'criterion': 'friedman_mse', 'learning_rate':...   5.0606  31.7491  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_result.sort_values(by=['RMSE'], axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
