{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprescindible\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to avoid some warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to draw some graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seaborn and matplotlib default theme\n",
    "sns.set_theme()\n",
    "_sns_plotting_contex_ = sns.plotting_context()\n",
    "sns.plotting_context('poster')\n",
    "\n",
    "# set seaborn and matplotlib style to ...\n",
    "# plt.style.use('classic')\n",
    "sns.mpl.rcParams['axes.titlesize'] = 18\n",
    "sns.mpl.rcParams['axes.labelsize'] = 14\n",
    "\n",
    "# to use HTML codes within IPpython.display function\n",
    "from IPython.display import HTML\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_figure(row, col, suptitle=None) :\n",
    "    u''' Activate matplot figure setting size and super title\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(row, col));\n",
    "    if suptitle != None :\n",
    "        fig.suptitle(suptitle, \n",
    "                     verticalalignment='center', fontsize='xx-large', fontweight='extra bold');\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"./data/blogData_train.csv\", header=None)\n",
    "data_raw.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49203, 281)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_classes = lambda v : 0 if v < 30 else (1 if v < 90 else (2 if v < 150 else (3 if v < 210 else 4)))\n",
    "# to_classes = lambda v : 0 if v < 30 else (1 if v < 90 else 2)\n",
    "to_classes = lambda v : 0 if v < 30 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_raw.iloc[:,0:280]\n",
    "y_train = data_raw.iloc[:,-1]\n",
    "\n",
    "y_train = y_train.apply(to_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = './data/test/'\n",
    "filelist = [os.path.join(filepath, filename) for filename in os.listdir(filepath) if os.path.isfile(os.path.join(filepath, filename))]\n",
    "\n",
    "test_raw = pd.DataFrame()\n",
    "\n",
    "for filename in filelist :\n",
    "    temp_raw = pd.read_csv(filename, header=None)\n",
    "    temp_raw.drop_duplicates(inplace=True)\n",
    "    test_raw = test_raw.append(temp_raw)\n",
    "\n",
    "X_test = test_raw.iloc[:,0:280]\n",
    "y_test = test_raw.iloc[:,-1]\n",
    "\n",
    "y_test = y_test.apply(to_classes)\n",
    "\n",
    "# using train scaler\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def classification_gridsearch_evaluate(X_train, y_train) :\n",
    "#     u'''\n",
    "#     '''\n",
    "if True :\n",
    "    class GS_Estimator :\n",
    "        u'''\n",
    "        '''\n",
    "\n",
    "        def __init__(self, name, estimator, gs_param_grid=None) :\n",
    "            self.name = name\n",
    "            self.estimator = estimator\n",
    "            self.gs_param_grid = gs_param_grid\n",
    "            self.gs_estimator = None\n",
    "\n",
    "            return        \n",
    "# ---\n",
    "    models = []\n",
    "\n",
    "    models.append(\n",
    "        GS_Estimator(\n",
    "            name='XGBoost Classifier 1',\n",
    "            estimator=xgb.XGBClassifier(),\n",
    "            gs_param_grid={\n",
    "                'eval_metric' : ['auc'], # \n",
    "                'gamma' : [0, 1], # (min_split_loss) minimum loss reduction\n",
    "                'learning_rate' : [0.1], # (eta) step size shrinkage\n",
    "                'max_depth' : [6], # maximum depth of tree\n",
    "                'n_estimators' : [100], \n",
    "                'n_jobs' : [-1], # use all processors\n",
    "                'objective' : ['binary:logistic'], # for binary classification \n",
    "                'random_state' : [127], \n",
    "                # 'subsample' : [0.1, 0.5, 1], # prevents overfitting\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    models.append(\n",
    "        GS_Estimator(\n",
    "            name='XGBoost Classifier 2',\n",
    "            estimator=xgb.XGBClassifier(),\n",
    "            gs_param_grid={\n",
    "                'eval_metric' : ['auc'], # \n",
    "                'gamma' : [0], # (min_split_loss) minimum loss reduction\n",
    "                'learning_rate' : [0.1], # (eta) step size shrinkage\n",
    "                'max_depth' : [8, 10], # maximum depth of tree\n",
    "                'n_estimators' : [500], \n",
    "                'n_jobs' : [-1], # use all processors\n",
    "                'objective' : ['binary:logistic'], # for binary classification \n",
    "                'random_state' : [127], \n",
    "                # 'subsample' : [0.1, 0.5, 1], # prevents overfitting\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# ---\n",
    "\n",
    "    gs_results = pd.DataFrame(columns=['model', 'best params', 'best score', 'train ROC AUC'])\n",
    "\n",
    "    for m in models :\n",
    "        scoring = 'roc_auc'\n",
    "        cv = StratifiedKFold(n_splits=2, random_state=11, shuffle=True)\n",
    "        gs = GridSearchCV(\n",
    "            estimator=m.estimator, # scikit-learn estimator interface\n",
    "            param_grid=m.gs_param_grid, # dictionart key=parametrer, value=list of paraameter posible values\n",
    "            scoring=scoring, # strategy to evaluate performance of cross-validated\n",
    "            n_jobs=-2, # jobs in parallel -2 : all processors minus one\n",
    "            refit=True, # refit estimator using best parameters\n",
    "            cv=cv, # cross-validated splitting strategy\n",
    "            return_train_score=False, # include training scores\n",
    "            verbose=3 # display fold parameters, score, time, ...\n",
    "        )\n",
    "        \n",
    "        print('Gridsearch para', m.name, '...')\n",
    "\n",
    "        gs.fit(X_train, y_train)\n",
    "        m.gs_estimator = gs.best_estimator_\n",
    "        \n",
    "        y_train_pred = gs.predict(X_train)\n",
    "        gs_train_roc_auc = ROUND(roc_auc_score(y_train, y_train_pred))\n",
    "\n",
    "        gs_results = gs_results.append(\n",
    "            pd.Series(\n",
    "                data=[m.name, \n",
    "                      gs.best_params_, \n",
    "                      gs.best_score_, \n",
    "                      gs_train_roc_auc\n",
    "                     ], \n",
    "                index=gs_results.columns\n",
    "                ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    pd.options.display.max_colwidth = 500 \n",
    "    display(gs_results.sort_values(by=['train ROC AUC'], axis='index'))\n",
    "    \n",
    "    # return\n",
    "\n",
    "# CAUTION !!!, it take a lot of time to run grid search\n",
    "# comment to hide grid search evaluate\n",
    "# classification_gridsearch_evaluate(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
