{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprescindible\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to avoid some warnings messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to draw some graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seaborn and matplotlib default theme\n",
    "sns.set_theme()\n",
    "_sns_plotting_contex_ = sns.plotting_context()\n",
    "sns.plotting_context('poster')\n",
    "\n",
    "# set seaborn and matplotlib style to ...\n",
    "# plt.style.use('classic')\n",
    "sns.mpl.rcParams['axes.titlesize'] = 18\n",
    "sns.mpl.rcParams['axes.labelsize'] = 14\n",
    "\n",
    "# to use HTML codes within IPpython.display function\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_train_read() :\n",
    "    u''' Reads and prepare data from blog feedback data train set\n",
    "    \n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(\"./data/blogData_train.csv\", header=None)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    header = pd.read_csv(\"./data/blogData_label.csv\", header=None)\n",
    "    header = list(header[0])\n",
    "    \n",
    "    if len(header) != data.shape[1] :\n",
    "        raise Exception('Los encabezados y la cantidad de caracter√≠sticas NO COINCIDE !!!')\n",
    "\n",
    "    data.columns = header\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = blogData_train_read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blogData_labels(data) :\n",
    "    u''' Create a dictionary with some keys associates to list of features in the final work dataframe\n",
    "    \n",
    "    '''\n",
    "    columns = list(data.columns)\n",
    "\n",
    "    labels = dict()\n",
    "\n",
    "    labels['sd_nc_total_before_BT'] = columns[0:5]\n",
    "    labels['sd_nc_24_before_BT'] = columns[5:10]\n",
    "    labels['sd_nc_between_24_48'] = columns[10:15]\n",
    "    labels['sd_nc_first_24_BT'] = columns[15:20]\n",
    "    labels['sd_nc_diff_24_48'] = columns[20:25]\n",
    "    \n",
    "    labels['sd_nl_total_before_BT'] = columns[25:30]\n",
    "    labels['sd_nl_24_before_BT'] = columns[30:35]\n",
    "    labels['sd_nl_between_24_48'] = columns[35:40]\n",
    "    labels['sd_nl_first_24_BT'] = columns[40:45]\n",
    "    labels['sd_nl_diff_24_48'] = columns[45:50]\n",
    "    \n",
    "    labels['nc_total_before_BT'] = columns[50:51]\n",
    "    labels['nc_24_before_BT'] = columns[51:52]\n",
    "    labels['nc_between_24_48'] = columns[52:53]\n",
    "    labels['nc_first_24_BT'] = columns[53:54]\n",
    "    labels['nc_diff_24_48'] = columns[54:55]\n",
    "    \n",
    "    labels['nl_total_before_BT'] = columns[55:56]\n",
    "    labels['nl_24_before_BT'] = columns[56:57]\n",
    "    labels['nl_between_24_48'] = columns[57:58]\n",
    "    labels['nl_first_24_BT'] = columns[58:59]\n",
    "    labels['nl_diff_24_48'] = columns[59:60]\n",
    "    \n",
    "    labels['nc'] = columns[50:55]\n",
    "    labels['nl'] = columns[55:60]\n",
    "\n",
    "    labels['timelength_post_BT'] = columns[60:61]\n",
    "    labels['length_post'] = columns[61:62]\n",
    "    \n",
    "    labels['tl_post'] = columns[60:62]\n",
    "\n",
    "    labels['frequent_word'] = columns[62:262]\n",
    "\n",
    "    labels['weekday_BT'] = columns[262:269]\n",
    "    labels['weekday_post'] = columns[269:276]\n",
    "    \n",
    "    labels['parents'] = columns[276:280]\n",
    "    labels['comments'] = columns[280:281]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = blogData_labels(data)\n",
    "target = 'comments'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = lambda v: round(v, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Regression_Models\"></a>\n",
    "### Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data.drop(columns=[target]).copy()\n",
    "y_train = data[target].copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(\n",
    "    data=scaler.transform(X_train), \n",
    "    columns=list(X_train.columns)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch para XGBoost Regressor L1 y L2 ...\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best params</th>\n",
       "      <th>best score</th>\n",
       "      <th>train RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor L1 y L2</td>\n",
       "      <td>{'eval_metric': 'rmse', 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 1000, 'n_jobs': -1, 'objective': 'reg:squarederror', 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000, 'subsample': 0.1}</td>\n",
       "      <td>-26.849064</td>\n",
       "      <td>23.4191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  \\\n",
       "0  XGBoost Regressor L1 y L2   \n",
       "\n",
       "                                                                                                                                                                                                                    best params  \\\n",
       "0  {'eval_metric': 'rmse', 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 8, 'n_estimators': 1000, 'n_jobs': -1, 'objective': 'reg:squarederror', 'random_state': 127, 'reg_alpha': 1000, 'reg_lambda': 1000, 'subsample': 0.1}   \n",
       "\n",
       "   best score  train RMSE  \n",
       "0  -26.849064     23.4191  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def gridsearch_evaluate(X_train, y_train) :\n",
    "    u'''\n",
    "    '''\n",
    "\n",
    "    class GS_Estimator :\n",
    "        u'''\n",
    "        '''\n",
    "\n",
    "        def __init__(self, name, estimator, gs_param_grid=None) :\n",
    "            self.name = name\n",
    "            self.estimator = estimator\n",
    "            self.gs_param_grid = gs_param_grid\n",
    "            self.gs_estimator = None\n",
    "\n",
    "            return        \n",
    "# ---\n",
    "    models = []\n",
    "\n",
    "    models.append(\n",
    "        GS_Estimator(\n",
    "            name='XGBoost Regressor L1 y L2',\n",
    "            estimator=xgb.XGBRegressor(),\n",
    "            gs_param_grid={\n",
    "                'eval_metric' : ['rmse'], # root mean square error\n",
    "                'gamma' : [1], # (min_split_loss) minimum loss reduction\n",
    "                'learning_rate' : [0.2], # (eta) step size shrinkage\n",
    "                'max_depth' : [8], # maximum depth of tree\n",
    "                'n_estimators' : [1000], \n",
    "                'n_jobs' : [-1], # use all processors\n",
    "                'objective' : ['reg:squarederror'], # regression with squared loss\n",
    "                'random_state' : [127], \n",
    "                'reg_alpha' : [1000], # L1 regularization\n",
    "                'reg_lambda' : [1000], # L2 regularization\n",
    "                'subsample' : [0.1], # prevents overfitting\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# ---\n",
    "\n",
    "    gs_results = pd.DataFrame(columns=['model', 'best params', 'best score', 'train RMSE'])\n",
    "\n",
    "    for m in models :\n",
    "        scoring = 'neg_root_mean_squared_error'\n",
    "        cv = StratifiedKFold(n_splits=2, random_state=11, shuffle=True)\n",
    "        gs = GridSearchCV(\n",
    "            estimator=m.estimator, # scikit-learn estimator interface\n",
    "            param_grid=m.gs_param_grid, # dictionart key=parametrer, value=list of paraameter posible values\n",
    "            scoring=scoring, # strategy to evaluate performance of cross-validated\n",
    "            n_jobs=-2, # jobs in parallel -2 : all processors minus one\n",
    "            refit=True, # refit estimator using best parameters\n",
    "            cv=cv, # cross-validated splitting strategy\n",
    "            return_train_score=False, # include training scores\n",
    "            verbose=1 # display fold parameters, score, time, ...\n",
    "        )\n",
    "        \n",
    "        print('Gridsearch para', m.name, '...')\n",
    "\n",
    "        gs.fit(X_train, y_train)\n",
    "        m.gs_estimator = gs.best_estimator_\n",
    "        \n",
    "        y_train_pred = gs.predict(X_train)\n",
    "        gs_train_rmse = ROUND(np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "        gs_results = gs_results.append(\n",
    "            pd.Series(\n",
    "                data=[m.name, \n",
    "                      gs.best_params_, \n",
    "                      gs.best_score_, \n",
    "                      gs_train_rmse\n",
    "                     ], \n",
    "                index=gs_results.columns\n",
    "                ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    pd.options.display.max_colwidth = 500 \n",
    "    display(gs_results.sort_values(by=['train RMSE'], axis='index'))\n",
    "    \n",
    "    return\n",
    "\n",
    "#\n",
    "gridsearch_evaluate(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
